{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Medical image segmentation with U-net \n",
    "\n",
    "## Lab Exercises\n",
    "\n",
    "This notebook contains lab exercises for sharpening spatial filters and Laplacian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build  a  semantic  segmentation  model  based  on  the  U-net  architecture.  You  can  use  an \n",
    "already implemented such model. You have examples in the following links: \n",
    " \n",
    "https://pyimagesearch.com/2022/02/21/u-net-image-segmentation-in-keras/ \n",
    "https://becominghuman.ai/u-net-architecture-explained-and-implementation-\n",
    "470a5095ad57 \n",
    "https://www.tensorflow.org/tutorials/images/segmentation \n",
    "https://asperbrothers.com/blog/image-segmentation/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# U-Net model implementation (encoder-decoder with skip connections)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, Model\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Helper metrics\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# U-Net model implementation (encoder-decoder with skip connections)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Helper metrics\n",
    "@tf.function\n",
    "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    y_pred_f = tf.cast(y_pred_f > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "@tf.function\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    y_pred_f = tf.cast(y_pred_f > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "# Basic U-Net blocks\n",
    "def conv_block(x, filters, kernel_size=3, activation='relu'):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation)(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same', activation=activation)(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, filters):\n",
    "    c = conv_block(x, filters)\n",
    "    p = layers.MaxPooling2D((2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def decoder_block(x, skip, filters):\n",
    "    x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "# U-Net builder\n",
    "def unet_model(input_shape=(128, 128, 1), num_classes=1, base_filters=64):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    c1, p1 = encoder_block(inputs, base_filters)\n",
    "    c2, p2 = encoder_block(p1, base_filters * 2)\n",
    "    c3, p3 = encoder_block(p2, base_filters * 4)\n",
    "    c4, p4 = encoder_block(p3, base_filters * 8)\n",
    "\n",
    "    bottleneck = conv_block(p4, base_filters * 16)\n",
    "\n",
    "    d4 = decoder_block(bottleneck, c4, base_filters * 8)\n",
    "    d3 = decoder_block(d4, c3, base_filters * 4)\n",
    "    d2 = decoder_block(d3, c2, base_filters * 2)\n",
    "    d1 = decoder_block(d2, c1, base_filters)\n",
    "\n",
    "    if num_classes == 1:\n",
    "        outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d1)\n",
    "        loss = 'binary_crossentropy'\n",
    "        metric_list = [dice_coef, iou, 'accuracy']\n",
    "    else:\n",
    "        outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(d1)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "        metric_list = [iou, 'accuracy']\n",
    "\n",
    "    model = Model(inputs, outputs, name='U-Net')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=metric_list)\n",
    "    return model\n",
    "\n",
    "# Example: build and show a summary for a small U-Net\n",
    "if __name__ == \"__main__\":\n",
    "    model = unet_model(input_shape=(128, 128, 1), num_classes=1, base_filters=32)\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download the Brain Tumor dataset from: \n",
    "https://drive.google.com/file/d/1RyOkJ7yb45P0NCvVqrE3mtmtVgVqwRji/view?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Brain Tumor dataset from Google Drive and extract\n",
    "# Installs gdown if not present, downloads the zip by file id, and extracts it.\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "try:\n",
    "    import gdown\n",
    "except Exception:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install --quiet gdown\n",
    "    import gdown\n",
    "\n",
    "file_id = \"1RyOkJ7yb45P0NCvVqrE3mtmtVgVqwRji\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output_zip = \"brain_tumor_dataset.zip\"\n",
    "extract_dir = \"brain_tumor_dataset\"\n",
    "\n",
    "if not os.path.exists(output_zip):\n",
    "    print('Downloading dataset...')\n",
    "    gdown.download(url, output_zip, quiet=False)\n",
    "else:\n",
    "    print(f\"{output_zip} already exists\")\n",
    "\n",
    "if os.path.exists(output_zip):\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(output_zip, 'r') as z:\n",
    "        print('Extracting...')\n",
    "        z.extractall(extract_dir)\n",
    "    print(f'Extracted to {extract_dir}/')\n",
    "else:\n",
    "    print('Download failed or file not found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Split  the  dataset  in  70%  train  images  (and  masks)  and  30%  test  images.  Use  as  many \n",
    "images as your computer allows you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into 70% train and 30% test (images and masks)\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Adjust these as needed\n",
    "dataset_dir = Path(\"brain_tumor_dataset\")  # folder created by the extraction step\n",
    "max_images = None  # set to an int to limit number of pairs used, or None to use all\n",
    "train_frac = 0.7\n",
    "seed = 42\n",
    "\n",
    "# find image files and mask files (common extensions)\n",
    "image_exts = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.bmp\")\n",
    "all_files = []\n",
    "for ext in image_exts:\n",
    "    all_files.extend(dataset_dir.rglob(ext))\n",
    "all_files = [p for p in all_files if p.is_file()]\n",
    "\n",
    "# simple heuristic to separate masks from images\n",
    "def is_mask(p: Path):\n",
    "    name = p.name.lower()\n",
    "    if \"mask\" in name or \"seg\" in name or \"gt\" in name or \"label\" in name:\n",
    "        return True\n",
    "    # also if parent folder name includes mask-like words\n",
    "    if any(k in p.parent.name.lower() for k in (\"mask\", \"masks\", \"seg\", \"labels\", \"groundtruth\", \"gt\")):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "masks = [p for p in all_files if is_mask(p)]\n",
    "images = [p for p in all_files if p not in masks]\n",
    "\n",
    "# Try to pair by stem (or by removing common suffixes like _mask)\n",
    "mask_map = {p.stem: p for p in masks}\n",
    "paired = []\n",
    "for img in images:\n",
    "    key = img.stem\n",
    "    if key in mask_map:\n",
    "        paired.append((img, mask_map[key]))\n",
    "        continue\n",
    "    # try removing common suffixes from mask stems\n",
    "    alt = key + \"_mask\"\n",
    "    if alt in mask_map:\n",
    "        paired.append((img, mask_map[alt]))\n",
    "        continue\n",
    "    # try the reverse (mask has suffix)\n",
    "    found = None\n",
    "    for m in masks:\n",
    "        if m.stem.startswith(key) or key.startswith(m.stem):\n",
    "            found = m\n",
    "            break\n",
    "    if found:\n",
    "        paired.append((img, found))\n",
    "\n",
    "# fallback: if no mask heuristics worked but equal number of images and masks, pair by sorted order\n",
    "if not paired and len(images) == len(masks) and len(images) > 0:\n",
    "    images_sorted = sorted(images)\n",
    "    masks_sorted = sorted(masks)\n",
    "    paired = list(zip(images_sorted, masks_sorted))\n",
    "\n",
    "if not paired:\n",
    "    print(\"No image/mask pairs found automatically. Found {} images and {} masks.\".format(len(images), len(masks)))\n",
    "    print(\"Please verify dataset structure (image files and mask files). Typical layout: dataset/images/ and dataset/masks/ or consistent filename suffixes like *_mask.png\")\n",
    "else:\n",
    "    print(f\"Found {len(paired)} image/mask pairs.\")\n",
    "\n",
    "# optionally limit\n",
    "if max_images is not None:\n",
    "    paired = paired[:max_images]\n",
    "\n",
    "# shuffle and split\n",
    "random.seed(seed)\n",
    "random.shuffle(paired)\n",
    "n = len(paired)\n",
    "n_train = int(n * train_frac)\n",
    "train_pairs = paired[:n_train]\n",
    "test_pairs = paired[n_train:]\n",
    "\n",
    "# create output dirs and copy files\n",
    "out_base = dataset_dir / \"data_split\"\n",
    "train_img_dir = out_base / \"train\" / \"images\"\n",
    "train_mask_dir = out_base / \"train\" / \"masks\"\n",
    "test_img_dir = out_base / \"test\" / \"images\"\n",
    "test_mask_dir = out_base / \"test\" / \"masks\"\n",
    "for d in (train_img_dir, train_mask_dir, test_img_dir, test_mask_dir):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for src, dst in train_pairs:\n",
    "    shutil.copy2(src, train_img_dir / src.name)\n",
    "    shutil.copy2(dst, train_mask_dir / dst.name)\n",
    "for src, dst in test_pairs:\n",
    "    shutil.copy2(src, test_img_dir / src.name)\n",
    "    shutil.copy2(dst, test_mask_dir / dst.name)\n",
    "\n",
    "# save file lists\n",
    "(out_base / \"train_list.txt\").write_text(\"\\n\".join(f\"{p[0]}\\t{p[1]}\" for p in train_pairs))\n",
    "(out_base / \"test_list.txt\").write_text(\"\\n\".join(f\"{p[0]}\\t{p[1]}\" for p in test_pairs))\n",
    "\n",
    "print(f\"Saved {len(train_pairs)} train pairs and {len(test_pairs)} test pairs under {out_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train  de  U-net  model  using  the  training  set  (if  necessary,  use  augmentation)  and  then \n",
    "segment  the  images  in  the  test  set.  Evaluate  the  efficacy  of  the  segmentation  task  by \n",
    "computing the mean pixel accuracy, mean Jaccard’s index (intersection over union) and \n",
    "mean Dice coefficient1. \n",
    " True Positive True NegativePixel Accuracy True Positive False Negative False Positive True Negative\n",
    "+= + + +   \n",
    " ' ( ) TPJaccard s index IoU Intersection over Union TP FN FP= = + + \n",
    " 2 TP 2 IntersectionDice coefficient 2 TP FN FP Union Intersection\n",
    "  = =  + + +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net training and evaluation pipeline\n",
    "# Assumes dataset directory with two subfolders: images/ and masks/ where filenames match.\n",
    "# Adjust DATA_DIR to point to the extracted dataset.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# ---------- User configuration ----------\n",
    "DATA_DIR = r\"./brain_tumor_dataset\"  # <-- set this to the extracted dataset root\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "SEED = 42\n",
    "# ----------------------------------------\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Helper: gather image/mask pairs\n",
    "def list_image_mask_pairs(data_dir):\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    masks_dir = os.path.join(data_dir, 'masks')\n",
    "    image_paths = sorted(glob.glob(os.path.join(images_dir, '*')))\n",
    "    pairs = []\n",
    "    for img_path in image_paths:\n",
    "        fname = os.path.basename(img_path)\n",
    "        mask_path = os.path.join(masks_dir, fname)\n",
    "        if os.path.exists(mask_path):\n",
    "            pairs.append((img_path, mask_path))\n",
    "    return pairs\n",
    "\n",
    "pairs = list_image_mask_pairs(DATA_DIR)\n",
    "print(f'Found {len(pairs)} image/mask pairs')\n",
    "if len(pairs) == 0:\n",
    "    raise RuntimeError('No data found. Update DATA_DIR to point to the dataset with images/ and masks/.')\n",
    "\n",
    "# Train/test split 70/30\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.30, random_state=SEED)\n",
    "print(f'Train: {len(train_pairs)}, Test: {len(test_pairs)}')\n",
    "\n",
    "# Loader\n",
    "def load_image(path, target_size=IMG_SIZE, grayscale=False):\n",
    "    img = Image.open(path)\n",
    "    if grayscale:\n",
    "        img = img.convert('L')\n",
    "    else:\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.BILINEAR)\n",
    "    arr = np.array(img)\n",
    "    if not grayscale and arr.ndim == 2:\n",
    "        arr = np.stack([arr]*3, axis=-1)\n",
    "    return arr\n",
    "\n",
    "# Prepare tf.data dataset\n",
    "def make_dataset(pairs, batch_size=BATCH_SIZE, augment=False, shuffle=True):\n",
    "    image_paths = [p for p,_ in pairs]\n",
    "    mask_paths = [m for _,m in pairs]\n",
    "\n",
    "    def _load(img_path, mask_path):\n",
    "        img = tf.numpy_function(lambda p: load_image(p.decode('utf-8'), IMG_SIZE, False), [img_path], tf.uint8)\n",
    "        mask = tf.numpy_function(lambda p: load_image(p.decode('utf-8'), IMG_SIZE, True), [mask_path], tf.uint8)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        mask = tf.cast(mask, tf.float32) / 255.0\n",
    "        # Ensure mask is binary single channel\n",
    "        mask = tf.where(mask > 0.5, 1.0, 0.0)\n",
    "        mask = tf.expand_dims(mask[...,0], -1)\n",
    "        return img, mask\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(image_paths), seed=SEED)\n",
    "    ds = ds.map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if augment:\n",
    "        def _augment(img, mask):\n",
    "            if tf.random.uniform(()) > 0.5:\n",
    "                img = tf.image.flip_left_right(img)\n",
    "                mask = tf.image.flip_left_right(mask)\n",
    "            if tf.random.uniform(()) > 0.5:\n",
    "                img = tf.image.flip_up_down(img)\n",
    "                mask = tf.image.flip_up_down(mask)\n",
    "            return img, mask\n",
    "        ds = ds.map(_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_pairs, augment=True)\n",
    "val_ds = make_dataset(test_pairs, augment=False, shuffle=False)\n",
    "\n",
    "# Simple U-Net\n",
    "def conv_block(x, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def up_conv_block(x, skip, filters):\n",
    "    x = layers.UpSampling2D(2)(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), n_filters=32):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    # Encoder\n",
    "    c1 = conv_block(inputs, n_filters)\n",
    "    p1 = layers.MaxPooling2D(2)(c1)\n",
    "    c2 = conv_block(p1, n_filters*2)\n",
    "    p2 = layers.MaxPooling2D(2)(c2)\n",
    "    c3 = conv_block(p2, n_filters*4)\n",
    "    p3 = layers.MaxPooling2D(2)(c3)\n",
    "    c4 = conv_block(p3, n_filters*8)\n",
    "    p4 = layers.MaxPooling2D(2)(c4)\n",
    "    # Bridge\n",
    "    b = conv_block(p4, n_filters*16)\n",
    "    # Decoder\n",
    "    u1 = up_conv_block(b, c4, n_filters*8)\n",
    "    u2 = up_conv_block(u1, c3, n_filters*4)\n",
    "    u3 = up_conv_block(u2, c2, n_filters*2)\n",
    "    u4 = up_conv_block(u3, c1, n_filters)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(u4)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_unet()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=6, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks)\n",
    "\n",
    "# Evaluation utilities\n",
    "def compute_metrics(model, pairs):\n",
    "    pix_accs = []\n",
    "    ious = []\n",
    "    dices = []\n",
    "    for img_path, mask_path in pairs:\n",
    "        img = load_image(img_path, IMG_SIZE, False)\n",
    "        gt = load_image(mask_path, IMG_SIZE, True)\n",
    "        img_in = np.expand_dims(img.astype(np.float32)/255.0, 0)\n",
    "        pred = model.predict(img_in)[0,...,0]\n",
    "        pred_bin = (pred > 0.5).astype(np.uint8)\n",
    "        gt_bin = (gt[...,0] > 127).astype(np.uint8)\n",
    "\n",
    "        # Pixel accuracy\n",
    "        acc = np.mean(pred_bin == gt_bin)\n",
    "        pix_accs.append(acc)\n",
    "\n",
    "        # IoU / Jaccard\n",
    "        intersection = np.logical_and(pred_bin, gt_bin).sum()\n",
    "        union = np.logical_or(pred_bin, gt_bin).sum()\n",
    "        iou = intersection / union if union != 0 else 1.0\n",
    "        ious.append(iou)\n",
    "\n",
    "        # Dice\n",
    "        dice = (2.0 * intersection) / (pred_bin.sum() + gt_bin.sum()) if (pred_bin.sum() + gt_bin.sum()) != 0 else 1.0\n",
    "        dices.append(dice)\n",
    "\n",
    "    return np.mean(pix_accs), np.mean(ious), np.mean(dices)\n",
    "\n",
    "mpa, miou, mdice = compute_metrics(model, test_pairs)\n",
    "print(f'Mean Pixel Accuracy: {mpa:.4f}')\n",
    "print(f'Mean IoU (Jaccard): {miou:.4f}')\n",
    "print(f'Mean Dice Coefficient: {mdice:.4f}')\n",
    "\n",
    "# Optionally save the model\n",
    "# model.save('unet_brain_tumor.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "5. Modify the U-net architecture, hoping to obtain better results. U-net variants \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual U-Net variant (BatchNorm + Dropout) to try improving results\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def conv_block_bn(x, filters, kernel_size=3, batchnorm=True):\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    if batchnorm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    if batchnorm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, batchnorm=True):\n",
    "    # projection for the residual path\n",
    "    res = layers.Conv2D(filters, 1, padding='same')(x)\n",
    "    if batchnorm:\n",
    "        res = layers.BatchNormalization()(res)\n",
    "    x = conv_block_bn(x, filters, kernel_size, batchnorm)\n",
    "    x = layers.add([x, res])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_resblock(x, filters, pool=True, dropout=0.0):\n",
    "    c = residual_block(x, filters)\n",
    "    if dropout and dropout > 0:\n",
    "        c = layers.Dropout(dropout)(c)\n",
    "    p = layers.MaxPooling2D((2, 2))(c) if pool else c\n",
    "    return c, p\n",
    "\n",
    "def decoder_resblock(x, skip, filters, dropout=0.0):\n",
    "    x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = residual_block(x, filters)\n",
    "    if dropout and dropout > 0:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "def build_resunet(input_shape=(128, 128, 3), n_filters=32, dropout=0.1):\n",
    "    inputs = layers.Input(input_shape)\n",
    "    c1, p1 = encoder_resblock(inputs, n_filters, pool=True, dropout=0.0)\n",
    "    c2, p2 = encoder_resblock(p1, n_filters * 2, dropout=dropout)\n",
    "    c3, p3 = encoder_resblock(p2, n_filters * 4, dropout=dropout)\n",
    "    c4, p4 = encoder_resblock(p3, n_filters * 8, dropout=dropout)\n",
    "\n",
    "    b = residual_block(p4, n_filters * 16)\n",
    "\n",
    "    d1 = decoder_resblock(b, c4, n_filters * 8, dropout=dropout)\n",
    "    d2 = decoder_resblock(d1, c3, n_filters * 4, dropout=dropout)\n",
    "    d3 = decoder_resblock(d2, c2, n_filters * 2, dropout=dropout)\n",
    "    d4 = decoder_resblock(d3, c1, n_filters, dropout=0.0)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(d4)\n",
    "    model = models.Model(inputs, outputs, name='ResUNet')\n",
    "    return model\n",
    "\n",
    "# Build and show a summary for the Residual U-Net variant\n",
    "# If IMG_SIZE is defined earlier in the notebook it will be used; otherwise default to (128,128)\n",
    "try:\n",
    "    _img_size = (IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "except Exception:\n",
    "    _img_size = (128, 128, 3)\n",
    "\n",
    "resunet = build_resunet(input_shape=_img_size, n_filters=32, dropout=0.1)\n",
    "resunet.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "6. Test U-Net on the dataset from Homwork 3 (Pratheepan dataset)  \n",
    " 1 https://towardsdatascience.com/how-accurate-is-image-segmentation-dd448f896388 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test U-Net on the Pratheepan dataset (Homework 3)\n",
    "# Set PRATHEEPAN_DIR to the root of the Pratheepan dataset (contains images/ and masks/ or files with mask in name)\n",
    "PRATHEEPAN_DIR = r\"./pratheepan_dataset\"  # <-- change this to your dataset path\n",
    "\n",
    "import os, glob\n",
    "\n",
    "def list_pairs_pratheepan(data_dir):\n",
    "    # Try standard images/ and masks/ subfolders first\n",
    "    img_exts = (\"*.jpg\",\"*.png\",\"*.jpeg\",\"*.bmp\",\"*.tif\")\n",
    "    images = []\n",
    "    masks = []\n",
    "    for ext in img_exts:\n",
    "        images += glob.glob(os.path.join(data_dir, 'images', ext))\n",
    "        masks += glob.glob(os.path.join(data_dir, 'masks', ext))\n",
    "    if images and masks:\n",
    "        img_map = {os.path.basename(p): p for p in images}\n",
    "        mask_map = {os.path.basename(p): p for p in masks}\n",
    "        pairs = [(img_map[n], mask_map[n]) for n in img_map.keys() if n in mask_map]\n",
    "        return pairs\n",
    "    # Fallback: search all files and use simple heuristics to separate masks\n",
    "    all_files = []\n",
    "    for ext in img_exts:\n",
    "        all_files += glob.glob(os.path.join(data_dir, '**', ext), recursive=True)\n",
    "    masks = [p for p in all_files if any(k in p.lower() for k in ('mask','seg','label','gt'))]\n",
    "    images = [p for p in all_files if p not in masks]\n",
    "    mask_map = {os.path.splitext(os.path.basename(m))[0]: m for m in masks}\n",
    "    pairs = []\n",
    "    for im in images:\n",
    "        key = os.path.splitext(os.path.basename(im))[0]\n",
    "        if key in mask_map:\n",
    "            pairs.append((im, mask_map[key]))\n",
    "    return pairs\n",
    "\n",
    "pairs = list_pairs_pratheepan(PRATHEEPAN_DIR)\n",
    "print(f'Found {len(pairs)} image/mask pairs in: {PRATHEEPAN_DIR}')\n",
    "if len(pairs) == 0:\n",
    "    raise RuntimeError('No pairs found. Update PRATHEEPAN_DIR to point to the dataset root.')\n",
    "\n",
    "# Ensure a model is available: try existing `model` variable or load saved model file\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    if os.path.exists('unet_brain_tumor.h5'):\n",
    "        from tensorflow.keras.models import load_model\n",
    "        model = load_model('unet_brain_tumor.h5', custom_objects={\n",
    "            'dice_coef': globals().get('dice_coef', None),\n",
    "            'iou': globals().get('iou', None)\n",
    "        })\n",
    "        print('Loaded model from unet_brain_tumor.h5')\n",
    "    else:\n",
    "        raise RuntimeError('No trained model found in variable `model` and unet_brain_tumor.h5 not present.')\n",
    "\n",
    "# Ensure load_image and IMG_SIZE exist, otherwise define a small helper\n",
    "try:\n",
    "    load_image\n",
    "except NameError:\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    def load_image(path, target_size=(128,128), grayscale=False):\n",
    "        img = Image.open(path)\n",
    "        if grayscale:\n",
    "            img = img.convert('L')\n",
    "        else:\n",
    "            img = img.convert('RGB')\n",
    "        img = img.resize(target_size, Image.BILINEAR)\n",
    "        return np.array(img)\n",
    "\n",
    "try:\n",
    "    IMG_SIZE\n",
    "except NameError:\n",
    "    IMG_SIZE = (128, 128)\n",
    "\n",
    "# Compute metrics over the dataset\n",
    "import numpy as np\n",
    "pix_accs = []\n",
    "ious = []\n",
    "dices = []\n",
    "for img_p, mask_p in pairs:\n",
    "    img = load_image(img_p, IMG_SIZE, False)\n",
    "    gt = load_image(mask_p, IMG_SIZE, True)\n",
    "    inp = np.expand_dims(img.astype('float32')/255.0, 0)\n",
    "    pred = model.predict(inp)[0,...,0]\n",
    "    pred_bin = (pred > 0.5).astype(np.uint8)\n",
    "    gt_bin = (gt[...,0] > 127).astype(np.uint8) if gt.ndim == 3 else (gt > 127).astype(np.uint8)\n",
    "\n",
    "    acc = np.mean(pred_bin == gt_bin)\n",
    "    pix_accs.append(acc)\n",
    "    intersection = np.logical_and(pred_bin, gt_bin).sum()\n",
    "    union = np.logical_or(pred_bin, gt_bin).sum()\n",
    "    ious.append(intersection / union if union != 0 else 1.0)\n",
    "    dices.append((2.0 * intersection) / (pred_bin.sum() + gt_bin.sum()) if (pred_bin.sum() + gt_bin.sum()) != 0 else 1.0)\n",
    "\n",
    "print(f'Mean Pixel Accuracy: {np.mean(pix_accs):.4f}')\n",
    "print(f'Mean IoU: {np.mean(ious):.4f}')\n",
    "print(f'Mean Dice: {np.mean(dices):.4f}')\n",
    "\n",
    "# Visualize a few examples\n",
    "import matplotlib.pyplot as plt\n",
    "n_show = min(3, len(pairs))\n",
    "for i in range(n_show):\n",
    "    img_p, mask_p = pairs[i]\n",
    "    img = load_image(img_p, IMG_SIZE, False)\n",
    "    gt = load_image(mask_p, IMG_SIZE, True)\n",
    "    pred = model.predict(np.expand_dims(img.astype('float32')/255.0, 0))[0,...,0]\n",
    "    pred_bin = (pred > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize=(9,3))\n",
    "    ax[0].imshow(img.astype('uint8'))\n",
    "    ax[0].set_title('Image'); ax[0].axis('off')\n",
    "    ax[1].imshow(gt[...,0] if gt.ndim==3 else gt, cmap='gray')\n",
    "    ax[1].set_title('Ground truth'); ax[1].axis('off')\n",
    "    ax[2].imshow(pred_bin, cmap='gray')\n",
    "    ax[2].set_title('Prediction'); ax[2].axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "U-net \n",
    "U-Net is a semantic segmentation convolutional neural network that was developed for \n",
    "biomedical image segmentation2. This model was developed to work with fewer training images \n",
    "(data  augmentation  with  elastic  deformations  reduces  the  number  of  annotated  images  required \n",
    "for  training)  and  yield  more  precise  segmentation.  Its  key  features  are  that  U-Net  learns \n",
    "segmentation in an end-to-end setting (one inputs an image and gets a segmentation map as the \n",
    "output).      U-Net  performs  classification  on  every  pixel  so  that  the  input  and  output  share  the \n",
    "same size. \n",
    "U-net is a special type of encoder-decoder network (see Figure 1): \n",
    "• encoder (left part of a “U”) –  encodes  image  into  an  abstract  representation  of  image \n",
    "features by applying a sequence of convolutional blocks that gradually decrease \n",
    "representation’s height and width but an increasing number  of  channels  that  correspond \n",
    "to image features. \n",
    "• decoder  (right  part  of  a  “U”)  –  decodes  image  representation  into  a  binary  mask  by \n",
    "applying a sequence of up-convolutions (NOT the same as deconvolution) that gradually \n",
    "increase representation’s height and width to the size of the original image and decreases \n",
    "the number of channels to the number of classes that we are segmenting \n",
    "• additionally,  U-Net  implements  skip  connections  that  connect  corresponding  levels  of \n",
    "encoder  and  decoder.  They  allow  the  model  not  to “lose” features extracted by earlier \n",
    "blocks of an encoder, which increases segmentation performance. \n",
    " \n",
    " \n",
    " 2  O.  Ronneberger,  P.  Fischer,  T.  Brox,  U-net:  Convolutional  networks  for  biomedical \n",
    "image segmentation, International Conference on Medical Image Computing and \n",
    "Computer-Assisted Intervention (2015) 234–241. \n",
    " \n",
    " \n",
    " \n",
    "Figure 1 – U-net architecture "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
