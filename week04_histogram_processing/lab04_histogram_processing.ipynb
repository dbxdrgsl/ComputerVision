{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04 - Keypoints\n",
    "\n",
    "## Lab Exercises\n",
    "\n",
    "This notebook contains lab exercises for Keypoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keypoints in an image are pixels that are more “important” than  other  pixels,  their \n",
    "neighborhood  contains  more  information.  \n",
    "***\n",
    "These  points  in  an  image  should  not  depend  on \n",
    "- illumination, \n",
    "- scale or geometrical, \n",
    "- affine distortions (rotations, translations, ...). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods that compute keypoints, such that: \n",
    "- Harris corner detection, \n",
    "- SURF, \n",
    "- SIFT, \n",
    "- ORB, \n",
    "- BRISK, \n",
    "- AKAZE,  \n",
    "- and  so  on.  \n",
    "\n",
    "Using  keypoint  extraction  was  applied  in  solving  problems  like  \n",
    "- human action recognition, \n",
    "- human pose estimation, \n",
    "- object detection and recognition, \n",
    "- panorama stitching, \n",
    "- video tracking, \n",
    "- and this list can continue. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Keypoints are employed in the following way: \n",
    "- usually in  the  same  time  with  keypoints  computations,  \n",
    "    - descriptors  with  information  around  these keypoints  are  also  calculated.  \n",
    "        - These  descriptors  are  feature  vectors  of  fixed  length  (64  or  128) with information on \n",
    "            - orientations, \n",
    "            - magnitude of gradient in a neighborhood \n",
    "                - around the keypoint.  \n",
    "- When  comparing  two  images,  \n",
    "    - a  keypoint  matching  procedure  is  performed  \n",
    "        - to  identify  the common parts.  \n",
    "\n",
    "A keypoint approach for solving a given task has the following steps: \n",
    "1. Covert to grayscale (if necessary); \n",
    "2. Keypoint detection; \n",
    "3. Descriptors computation; \n",
    "4. (Keypoints, descriptors) matching; \n",
    "5. Analyze  the  results  provided  by  the  previous  steps  in  the  context  of  the  problem  to  be \n",
    "solved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Problems to be approached for this lab: \n",
    "\n",
    "\n",
    "2. Consider  the  following  dataset  (link  here1).  It  contains  images  from  three  locations  in \n",
    "Iaşi. \n",
    "a. For  all  the  images  in  this  dataset  compute  the  keypoints  and  the  corresponding \n",
    "descriptors, using different methods for keypoints detection. \n",
    "b. For each image in the test set perform the matching process with all the images from \n",
    "the train set. Use both matching procedures implemented in OpenCV. \n",
    "c. Compute  the  set  of  images  from  the  training  set  that  have  maximum  number  of \n",
    "matched keypoints with the test image. \n",
    "d. If the set computed in step c. has only one image, that image provides the label for the \n",
    "test  image.  If  the  set  contains  more  than  one  image,  perform  a  voting  procedure  to \n",
    "assign a label (location) to the test image. In case of parity, assign the label randomly \n",
    "or find another way to assign the label. Display/print the name of the image for which \n",
    "the parity situation occurred. \n",
    "e. Compute the accuracy of the classification process and the confusion matrix. \n",
    "Remarks: 1) Test different keypoints extracting methods and different matching \n",
    "procedures. \n",
    "2)  If,  for  an  image,  the  keypoints  detection  method  does  not  compute  any  keypoint, \n",
    "modify  some  parameters  of  this  method  until  it  computes  at  least  one  keypoint.  If  for \n",
    "certain keypoints methods this type of computation isn’t possible, display a message that \n",
    "states  this  fact,  and  continue  with  the  computations.  A  test  image  with  no  keypoints \n",
    "cannot  be  classified  (or  assign  a  random  label)  or  it  cannot  be  used  in  the  classification \n",
    "process if the image belongs to the training set. \n",
    "Useful links: \n",
    "https://www.cs.utah.edu/~srikumar/cv_spring2017_files/Keypoints&Descriptors.pdf \n",
    "https://www.mdpi.com/2223-7747/10/9/1791/pdf \n",
    "OpenCV:  \n",
    "https://opencv24-python-\n",
    "tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_t\n",
    "able_of_contents_feature2d.html \n",
    " 1 The images from this archive are part of a larger dataset created by the researchers of the Institute of \n",
    "Computer Science, Romanian Academy, Iaşi branch. \n",
    " \n",
    "https://opencv24-python-\n",
    "tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_matcher/py_matcher.html \n",
    "https://machinelearningmastery.com/opencv_sift_surf_orb_keypoints/ \n",
    "https://learnopencv.com/object-keypoint-similarity/ \n",
    "Original images \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "Images with SURF keypoints \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "Images with matched keypoints \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "5 matched keypoints \n",
    " \n",
    " \n",
    " \n",
    "  \n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute keypoints for an image using different methods (Harris corner detection, SIFT, \n",
    "SURF, ...).  Use as many keypoints detection methods as the OpenCV library allows (at \n",
    "least 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common setup loaded. Available detectors: ['HARRIS', 'SIFT', 'ORB', 'BRISK', 'AKAZE']\n"
     ]
    }
   ],
   "source": [
    "# Common setup for Lab 04 - Keypoints\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Create available detectors\n",
    "def create_detectors():\n",
    "    dets = {}\n",
    "    # Harris handled separately\n",
    "    dets['HARRIS'] = 'HARRIS'\n",
    "    # SIFT\n",
    "    try:\n",
    "        dets['SIFT'] = cv2.SIFT_create()\n",
    "    except Exception:\n",
    "        try:\n",
    "            dets['SIFT'] = cv2.xfeatures2d.SIFT_create()\n",
    "        except Exception:\n",
    "            pass\n",
    "    # SURF (may be unavailable)\n",
    "    try:\n",
    "        dets['SURF'] = cv2.xfeatures2d.SURF_create()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # ORB\n",
    "    try:\n",
    "        dets['ORB'] = cv2.ORB_create(nfeatures=1000)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # BRISK\n",
    "    try:\n",
    "        dets['BRISK'] = cv2.BRISK_create()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # AKAZE\n",
    "    try:\n",
    "        dets['AKAZE'] = cv2.AKAZE_create()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return dets\n",
    "\n",
    "DETECTORS = create_detectors()\n",
    "\n",
    "# Harris corner detector returning list of cv2.KeyPoint\n",
    "def harris_keypoints(img_gray, blockSize=2, ksize=3, k=0.04, thresh=0.01):\n",
    "    dst = cv2.cornerHarris(np.float32(img_gray), blockSize, ksize, k)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "    keypoints = []\n",
    "    # normalize and threshold\n",
    "    maxv = dst.max() if dst.size else 0\n",
    "    if maxv == 0:\n",
    "        return []\n",
    "    # pick points greater than thresh*max\n",
    "    ys, xs = np.where(dst > thresh * maxv)\n",
    "    for (x, y) in zip(xs, ys):\n",
    "        keypoints.append(cv2.KeyPoint(float(x), float(y), _size=ksize))\n",
    "    return keypoints\n",
    "\n",
    "# Generic detect+compute wrapper\n",
    "def detect_and_compute(detector, img_gray):\n",
    "    if detector == 'HARRIS':\n",
    "        kp = harris_keypoints(img_gray)\n",
    "        # Harris has no descriptors\n",
    "        return kp, None\n",
    "    try:\n",
    "        kp, des = detector.detectAndCompute(img_gray, None)\n",
    "    except Exception:\n",
    "        # some detectors may not implement detectAndCompute signature exactly\n",
    "        try:\n",
    "            kp = detector.detect(img_gray)\n",
    "            des = None\n",
    "        except Exception:\n",
    "            kp, des = [], None\n",
    "    return kp, des\n",
    "\n",
    "# Draw keypoints with matplotlib (RGB display)\n",
    "def draw_keypoints(img_bgr, keypoints, title=None, figsize=(8,6)):\n",
    "    img_kp = cv2.drawKeypoints(img_bgr, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    img_rgb = cv2.cvtColor(img_kp, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "\n",
    "# Count keypoints in an MxN grid\n",
    "def keypoints_grid_count(keypoints, img_shape, grid=(8,8)):\n",
    "    h, w = img_shape[:2]\n",
    "    gx, gy = grid\n",
    "    counts = np.zeros((gy, gx), dtype=int)\n",
    "    for kp in keypoints:\n",
    "        x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "        ix = min(x * gx // w, gx - 1)\n",
    "        iy = min(y * gy // h, gy - 1)\n",
    "        counts[iy, ix] += 1\n",
    "    return counts\n",
    "\n",
    "# Blurring / rotation / noise helpers\n",
    "def blur_mean(img, ksize=(5,5)):\n",
    "    return cv2.blur(img, ksize)\n",
    "\n",
    "def blur_gaussian(img, ksize=(5,5), sigma=1.0):\n",
    "    return cv2.GaussianBlur(img, ksize, sigma)\n",
    "\n",
    "def rotate_image(img, angle_deg):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle_deg, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def add_gaussian_noise(img, sigma=10):\n",
    "    if img.dtype != np.uint8:\n",
    "        img_u8 = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_u8 = img.copy()\n",
    "    noise = np.random.normal(0, sigma, img_u8.shape).astype(np.int16)\n",
    "    out = img_u8.astype(np.int16) + noise\n",
    "    out = np.clip(out, 0, 255).astype(np.uint8)\n",
    "    return out\n",
    "\n",
    "# Matching utilities\n",
    "def _choose_norm(des1, des2):\n",
    "    # float descriptors (SIFT/SURF) -> L2, binary descriptors -> Hamming\n",
    "    if des1 is None or des2 is None:\n",
    "        return cv2.NORM_L2\n",
    "    if des1.dtype == np.float32 or des2.dtype == np.float32:\n",
    "        return cv2.NORM_L2\n",
    "    return cv2.NORM_HAMMING\n",
    "\n",
    "def bf_match(des1, des2, cross_check=False):\n",
    "    norm = _choose_norm(des1, des2)\n",
    "    bf = cv2.BFMatcher(norm, crossCheck=cross_check)\n",
    "    if des1 is None or des2 is None:\n",
    "        return []\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches\n",
    "\n",
    "def knn_match(des1, des2, ratio=0.75, k=2):\n",
    "    norm = _choose_norm(des1, des2)\n",
    "    bf = cv2.BFMatcher(norm, crossCheck=False)\n",
    "    if des1 is None or des2 is None:\n",
    "        return []\n",
    "    raw = bf.knnMatch(des1, des2, k=k)\n",
    "    good = []\n",
    "    for m_n in raw:\n",
    "        if len(m_n) != 2:\n",
    "            continue\n",
    "        m, n = m_n\n",
    "        if m.distance < ratio * n.distance:\n",
    "            good.append(m)\n",
    "    return good\n",
    "\n",
    "# Compute keypoints and descriptors for all available detectors\n",
    "def compute_all_detectors(img_bgr):\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    results = {}\n",
    "    for name, det in DETECTORS.items():\n",
    "        kp, des = detect_and_compute(det, img_gray) if det != 'HARRIS' else (harris_keypoints(img_gray), None)\n",
    "        if not kp:\n",
    "            print(f\"Warning: detector {name} returned 0 keypoints\")\n",
    "        results[name] = {'keypoints': kp, 'descriptors': des}\n",
    "    return results\n",
    "\n",
    "# Example loader for local image path\n",
    "def load_image(path):\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not read image: {path}\")\n",
    "    return img\n",
    "\n",
    "print('Common setup loaded. Available detectors:', list(DETECTORS.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "a. Plot the image with marked keypoints. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please set example_path to a valid image file in the notebook workspace and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# Experiment cell: compute keypoints, grid counts, and perform blur/rotate/noise matching\n",
    "from pathlib import Path\n",
    "\n",
    "def display_grid_counts(counts, title=None):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.title(title if title else '')\n",
    "    plt.imshow(counts, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def match_and_report(orig_res, mod_res, detector_name, img_orig, img_mod, top_draw=20):\n",
    "    des1 = orig_res[detector_name]['descriptors']\n",
    "    des2 = mod_res[detector_name]['descriptors']\n",
    "    print(f\"Detector: {detector_name}\")\n",
    "    if des1 is None or des2 is None:\n",
    "        print(\"  No descriptors available for matching (skipping).\")\n",
    "        return\n",
    "    m_bf = bf_match(des1, des2, cross_check=True)\n",
    "    m_knn = knn_match(des1, des2, ratio=0.75)\n",
    "    print(f\"  BF matches (crossCheck): {len(m_bf)}\")\n",
    "    print(f\"  kNN (ratio test) good matches: {len(m_knn)}\")\n",
    "    # draw top matches for visualization\n",
    "    if len(m_bf) > 0:\n",
    "        matches_to_draw = m_bf[:top_draw]\n",
    "        kp1 = orig_res[detector_name]['keypoints']\n",
    "        kp2 = mod_res[detector_name]['keypoints']\n",
    "        img_draw = cv2.drawMatches(img_orig, kp1, img_mod, kp2, matches_to_draw, None,\n",
    "                                   flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def run_experiments(image_path):\n",
    "    img = load_image(image_path)\n",
    "    print('Image loaded:', image_path)\n",
    "\n",
    "    # compute for original\n",
    "    orig_res = compute_all_detectors(img)\n",
    "\n",
    "    # a) Plot image with keypoints for each detector\n",
    "    for name, r in orig_res.items():\n",
    "        print(f\"\\n{name}: {len(r['keypoints'])} keypoints\")\n",
    "        draw_keypoints(img, r['keypoints'], title=f\"{name} - {len(r['keypoints'])} keypoints\")\n",
    "        counts = keypoints_grid_count(r['keypoints'], img.shape, grid=(8,8))\n",
    "        display_grid_counts(counts, title=f\"{name} - 8x8 grid counts\")\n",
    "\n",
    "    # Prepare modifications sets\n",
    "    blurs = [\n",
    "        ('mean_k5', blur_mean(img, (5,5))),\n",
    "        ('mean_k9', blur_mean(img, (9,9))),\n",
    "        ('gauss_k5_s1', blur_gaussian(img, (5,5), sigma=1.0)),\n",
    "        ('gauss_k9_s2', blur_gaussian(img, (9,9), sigma=2.0)),\n",
    "    ]\n",
    "    rotations = [\n",
    "        ('rot_15', rotate_image(img, 15)),\n",
    "        ('rot_45', rotate_image(img, 45)),\n",
    "        ('rot_90', rotate_image(img, 90)),\n",
    "    ]\n",
    "    noises = [\n",
    "        ('noise_s5', add_gaussian_noise(img, sigma=5)),\n",
    "        ('noise_s15', add_gaussian_noise(img, sigma=15)),\n",
    "        ('noise_s30', add_gaussian_noise(img, sigma=30)),\n",
    "    ]\n",
    "\n",
    "    # c) Blur experiments: compute detectors on blurred and match against original\n",
    "    for name_mod, img_mod in blurs:\n",
    "        print(f\"\\n=== BLUR: {name_mod} ===\")\n",
    "        mod_res = compute_all_detectors(img_mod)\n",
    "        for det in orig_res.keys():\n",
    "            match_and_report(orig_res, mod_res, det, img, img_mod)\n",
    "\n",
    "    # d) Rotation experiments\n",
    "    for name_mod, img_mod in rotations:\n",
    "        print(f\"\\n=== ROTATION: {name_mod} ===\")\n",
    "        mod_res = compute_all_detectors(img_mod)\n",
    "        for det in orig_res.keys():\n",
    "            match_and_report(orig_res, mod_res, det, img, img_mod)\n",
    "\n",
    "    # e) Noise experiments\n",
    "    for name_mod, img_mod in noises:\n",
    "        print(f\"\\n=== NOISE: {name_mod} ===\")\n",
    "        mod_res = compute_all_detectors(img_mod)\n",
    "        for det in orig_res.keys():\n",
    "            match_and_report(orig_res, mod_res, det, img, img_mod)\n",
    "\n",
    "\n",
    "# Example: change this path to a valid image on disk\n",
    "example_path = Path.cwd() / 'example.jpg'\n",
    "if example_path.exists():\n",
    "    run_experiments(str(example_path))\n",
    "else:\n",
    "    print('Please set example_path to a valid image file in the notebook workspace and re-run this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "b.  Compare the keypoints detection methods analyzing the number of computed keypoints and their positioning in the image. \n",
    "For the positioning comparisons, divide the  image  in  8  ×  8  non-overlapping  regions,  and  count  the  number  of  keypoints  in each region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part b) Compare detectors: total keypoints and 8x8 grid positioning\n",
    "from pathlib import Path\n",
    "\n",
    "def compare_detectors_on_image(image_path, grid=(8,8)):\n",
    "    img = load_image(image_path)\n",
    "    results = compute_all_detectors(img)\n",
    "\n",
    "    for name, r in results.items():\n",
    "        kp = r['keypoints']\n",
    "        cnt = len(kp)\n",
    "        print(f\"{name}: {cnt} keypoints\")\n",
    "        # show keypoints over image\n",
    "        draw_keypoints(img, kp, title=f\"{name} - {cnt} keypoints\", figsize=(6,4))\n",
    "        # compute and display 8x8 grid counts\n",
    "        counts = keypoints_grid_count(kp, img.shape, grid=grid)\n",
    "        display_grid_counts(counts, title=f\"{name} - {grid[0]}x{grid[1]} grid counts\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage: change path if needed\n",
    "example_path = Path.cwd() / 'example.jpg'\n",
    "if example_path.exists():\n",
    "    compare_detectors_on_image(str(example_path))\n",
    "else:\n",
    "    print('Please set example_path to a valid image file in the notebook workspace and re-run this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "c. Blur the image. Compute its keypoints. Match the keypoints of the original image and the blurred one using brute force and the kNN based methods. \n",
    "Monitor the number of matched keypoints. \n",
    "Use different types of blurring (with mean filters, with Gaussian filters of different size). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part c) Blur experiments: compute keypoints for blurred images and match to original\n",
    "from pathlib import Path\n",
    "\n",
    "def blur_experiments(image_path, top_draw=20):\n",
    "    img = load_image(image_path)\n",
    "    print('Image loaded for blur experiments:', image_path)\n",
    "\n",
    "    # compute for original\n",
    "    orig_res = compute_all_detectors(img)\n",
    "\n",
    "    # Different blurring operations\n",
    "    blurs = [\n",
    "        ('mean_k5', blur_mean(img, (5,5))),\n",
    "        ('mean_k9', blur_mean(img, (9,9))),\n",
    "        ('gauss_k5_s1', blur_gaussian(img, (5,5), sigma=1.0)),\n",
    "        ('gauss_k9_s2', blur_gaussian(img, (9,9), sigma=2.0)),\n",
    "    ]\n",
    "\n",
    "    for name_mod, img_mod in blurs:\n",
    "        print(f\"\\n=== BLUR: {name_mod} ===\")\n",
    "        mod_res = compute_all_detectors(img_mod)\n",
    "\n",
    "        for det in orig_res.keys():\n",
    "            kp1 = orig_res[det]['keypoints']\n",
    "            kp2 = mod_res[det]['keypoints']\n",
    "            des1 = orig_res[det]['descriptors']\n",
    "            des2 = mod_res[det]['descriptors']\n",
    "            n1 = len(kp1)\n",
    "            n2 = len(kp2)\n",
    "\n",
    "            # If descriptors are missing, skip matching but report counts\n",
    "            if des1 is None or des2 is None:\n",
    "                print(f\"  {det}: kp_orig={n1}, kp_blur={n2} -> no descriptors, skipping matching\")\n",
    "                continue\n",
    "\n",
    "            # BF match with cross-check and kNN with ratio test\n",
    "            m_bf = bf_match(des1, des2, cross_check=True)\n",
    "            m_knn = knn_match(des1, des2, ratio=0.75)\n",
    "\n",
    "            print(f\"  {det}: kp_orig={n1}, kp_blur={n2}, BFmatches={len(m_bf)}, kNNmatches={len(m_knn)}\")\n",
    "\n",
    "            # Visualize top BF matches if available\n",
    "            if len(m_bf) > 0:\n",
    "                matches_to_draw = m_bf[:top_draw]\n",
    "                img_draw = cv2.drawMatches(img, kp1, img_mod, kp2, matches_to_draw, None,\n",
    "                                           flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                plt.figure(figsize=(10,5))\n",
    "                plt.title(f\"{det} matches - {name_mod} (BF top {len(matches_to_draw)})\")\n",
    "                plt.axis('off')\n",
    "                plt.imshow(cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# Example usage: change path if needed\n",
    "example_path = Path.cwd() / 'example.jpg'\n",
    "if example_path.exists():\n",
    "    blur_experiments(str(example_path))\n",
    "else:\n",
    "    print('Please set example_path to a valid image file in the notebook workspace and re-run this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "d. Rotate  the  original  image  and  then  perform  the  same  computations/comparisons as those described in step c. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please set example_path to a valid image file in the notebook workspace and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# Part d) Rotation experiments: rotate image, compute keypoints/descriptors and match against original\n",
    "from pathlib import Path\n",
    "\n",
    "def rotation_experiments(image_path, angles=(15,45,90), top_draw=20):\n",
    "    img = load_image(image_path)\n",
    "    print('Image loaded:', image_path)\n",
    "\n",
    "    # compute for original\n",
    "    orig_res = compute_all_detectors(img)\n",
    "\n",
    "    for ang in angles:\n",
    "        print(f\"\\n=== ROTATION: {ang} degrees ===\")\n",
    "        img_rot = rotate_image(img, ang)\n",
    "        mod_res = compute_all_detectors(img_rot)\n",
    "\n",
    "        for det_name in orig_res.keys():\n",
    "            kp1 = orig_res[det_name]['keypoints']\n",
    "            kp2 = mod_res[det_name]['keypoints']\n",
    "            des1 = orig_res[det_name]['descriptors']\n",
    "            des2 = mod_res[det_name]['descriptors']\n",
    "\n",
    "            print(f\"Detector: {det_name} | orig_kp={len(kp1)} rot_kp={len(kp2)}\")\n",
    "            if des1 is None or des2 is None:\n",
    "                print(\"  No descriptors available for matching (skipping).\")\n",
    "                continue\n",
    "\n",
    "            m_bf = bf_match(des1, des2, cross_check=True)\n",
    "            m_knn = knn_match(des1, des2, ratio=0.75)\n",
    "            print(f\"  BF matches (crossCheck): {len(m_bf)}\")\n",
    "            print(f\"  kNN (ratio test) good matches: {len(m_knn)}\")\n",
    "\n",
    "            # draw top BF matches\n",
    "            if len(m_bf) > 0:\n",
    "                matches_to_draw = m_bf[:top_draw]\n",
    "                img_draw = cv2.drawMatches(img, kp1, img_rot, kp2, matches_to_draw, None,\n",
    "                                           flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                plt.figure(figsize=(12,6))\n",
    "                plt.axis('off')\n",
    "                plt.title(f\"{det_name} - top {len(matches_to_draw)} matches (rot {ang} deg)\")\n",
    "                plt.imshow(cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "                plt.show()\n",
    "\n",
    "# Example usage: change path if needed\n",
    "example_path = Path.cwd() / 'example.jpg'\n",
    "if example_path.exists():\n",
    "    rotation_experiments(str(example_path), angles=(15,45,90), top_draw=20)\n",
    "else:\n",
    "    print('Please set example_path to a valid image file in the notebook workspace and re-run this cell.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "e. Add Gaussian noise to the original image. Perform the same analysis as that described in  step  c.  Use  different  amount  of  noise  (different  values  for  the  standard  deviation, Add different noise to an image | TheAILearner). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part e) Noise experiments: add Gaussian noise to the image and match to original\n",
    "from pathlib import Path\n",
    "\n",
    "def noise_experiments(image_path, sigmas=(5, 15, 30), top_draw=20):\n",
    "    img = load_image(image_path)\n",
    "    print('Image loaded for noise experiments:', image_path)\n",
    "\n",
    "    # compute for original\n",
    "    orig_res = compute_all_detectors(img)\n",
    "\n",
    "    # prepare noisy versions\n",
    "    noises = [(f'noise_s{int(s)}', add_gaussian_noise(img, sigma=s)) for s in sigmas]\n",
    "\n",
    "    for name_mod, img_mod in noises:\n",
    "        print(f\"\\n=== NOISE: {name_mod} ===\")\n",
    "        mod_res = compute_all_detectors(img_mod)\n",
    "\n",
    "        for det in orig_res.keys():\n",
    "            kp1 = orig_res[det]['keypoints']\n",
    "            kp2 = mod_res[det]['keypoints']\n",
    "            des1 = orig_res[det]['descriptors']\n",
    "            des2 = mod_res[det]['descriptors']\n",
    "            n1 = len(kp1)\n",
    "            n2 = len(kp2)\n",
    "\n",
    "            if des1 is None or des2 is None:\n",
    "                print(f\"  {det}: kp_orig={n1}, kp_noise={n2} -> no descriptors, skipping matching\")\n",
    "                continue\n",
    "\n",
    "            # BF match with cross-check and kNN with ratio test\n",
    "            m_bf = bf_match(des1, des2, cross_check=True)\n",
    "            m_knn = knn_match(des1, des2, ratio=0.75)\n",
    "\n",
    "            print(f\"  {det}: kp_orig={n1}, kp_noise={n2}, BFmatches={len(m_bf)}, kNNmatches={len(m_knn)}\")\n",
    "\n",
    "            # Visualize top BF matches if available\n",
    "            if len(m_bf) > 0:\n",
    "                matches_to_draw = m_bf[:top_draw]\n",
    "                img_draw = cv2.drawMatches(img, kp1, img_mod, kp2, matches_to_draw, None,\n",
    "                                           flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                plt.figure(figsize=(10,5))\n",
    "                plt.title(f\"{det} matches - {name_mod} (BF top {len(matches_to_draw)})\")\n",
    "                plt.axis('off')\n",
    "                plt.imshow(cv2.cvtColor(img_draw, cv2.COLOR_BGR2RGB))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# Example usage: change path if needed\n",
    "example_path = Path.cwd() / 'example.jpg'\n",
    "if example_path.exists():\n",
    "    noise_experiments(str(example_path))\n",
    "else:\n",
    "    print('Please set example_path to a valid image file in the notebook workspace and re-run this cell.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
